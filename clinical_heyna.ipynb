{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Lhjoaw0y0Ura",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4dd87a4-177a-4725-e6a6-066172b4d752"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Credit: Notebook adapted from [HyenaDNA](https://colab.research.google.com/drive/1wyVEQd4R3HYLTUOXEEQmp_I8aNC_aLhL?usp=sharing#scrollTo=OJHCegJvtASc)."
      ],
      "metadata": {
        "id": "YtK1MG3F-OWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision\n",
        "!pip install transformers\n",
        "!pip install einops\n",
        "!pip install OmegaConf"
      ],
      "metadata": {
        "id": "rm2jBkFnUduJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import torch\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from functools import partial\n",
        "from einops import rearrange\n",
        "from typing import Optional\n",
        "from functools import partial\n",
        "from torch import Tensor\n",
        "from torchvision.ops import StochasticDepth\n",
        "from collections import namedtuple\n",
        "import yaml\n",
        "from random import random\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "from random import random\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "349edbzrUF2c",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture\n"
      ],
      "metadata": {
        "id": "Et3PVlnm9XPE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FhGpKGzsRhzI",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Hyena layer\n",
        "\n",
        "\n",
        "def fftconv(u, k, D):\n",
        "    \"\"\"\n",
        "    We apply a convolution through the fourier domain (from the Convolution Theorem)\n",
        "\n",
        "    \"\"\"\n",
        "    seqlen = u.shape[-1]\n",
        "    fft_size = 2 * seqlen\n",
        "\n",
        "    k_f = torch.fft.rfft(k, n=fft_size) / fft_size\n",
        "    u_f = torch.fft.rfft(u.to(dtype=k.dtype), n=fft_size)\n",
        "\n",
        "    if len(u.shape) > 3: k_f = k_f.unsqueeze(1)\n",
        "    y = torch.fft.irfft(u_f * k_f, n=fft_size, norm='forward')[..., :seqlen]\n",
        "\n",
        "    out = y + u * D.unsqueeze(-1)\n",
        "    return out.to(dtype=u.dtype)\n",
        "\n",
        "\n",
        "@torch.jit.script\n",
        "def mul_sum(q, y):\n",
        "    return (q * y).sum(dim=1)\n",
        "\n",
        "class OptimModule(nn.Module):\n",
        "    \"\"\" Interface for Module that allows registering buffers/parameters with configurable optimizer hyperparameters \"\"\"\n",
        "\n",
        "    def register(self, name, tensor, lr=None, wd=0.0):\n",
        "        \"\"\"Register a tensor with a configurable learning rate and 0 weight decay\"\"\"\n",
        "\n",
        "        if lr == 0.0:\n",
        "            self.register_buffer(name, tensor)\n",
        "        else:\n",
        "            self.register_parameter(name, nn.Parameter(tensor))\n",
        "\n",
        "            optim = {}\n",
        "            if lr is not None: optim[\"lr\"] = lr\n",
        "            if wd is not None: optim[\"weight_decay\"] = wd\n",
        "            setattr(getattr(self, name), \"_optim\", optim)\n",
        "\n",
        "\n",
        "class Sin(nn.Module):\n",
        "    \"\"\"The Sin activation function for the Hyena Filter function.\"\"\"\n",
        "    def __init__(self, dim, w=10, train_freq=True):\n",
        "        super().__init__()\n",
        "        self.freq = nn.Parameter(w * torch.ones(1, dim)) if train_freq else w * torch.ones(1, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sin(self.freq * x)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(OptimModule):\n",
        "    def __init__(self, emb_dim: int, seq_len: int, lr_pos_emb: float=1e-5, **kwargs):\n",
        "        \"\"\"Complex exponential positional embeddings for Hyena filters.\"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.seq_len = seq_len\n",
        "        # The time embedding fed to the filteres is normalized so that t_f = 1\n",
        "        t = torch.linspace(0, 1, self.seq_len)[None, :, None] # 1, L, 1\n",
        "\n",
        "        if emb_dim > 1:\n",
        "            bands = (emb_dim - 1) // 2\n",
        "        # To compute the right embeddings we use the \"proper\" linspace\n",
        "        t_rescaled = torch.linspace(0, seq_len - 1, seq_len)[None, :, None]\n",
        "        w = 2 * math.pi * t_rescaled / seq_len # 1, L, 1\n",
        "\n",
        "        f = torch.linspace(1e-4, bands - 1, bands)[None, None]\n",
        "        z = torch.exp(-1j * f * w)\n",
        "        z = torch.cat([t, z.real, z.imag], dim=-1)\n",
        "        self.register(\"z\", z, lr=lr_pos_emb)\n",
        "        self.register(\"t\", t, lr=0.0)\n",
        "\n",
        "    def forward(self, L):\n",
        "        return self.z[:, :L], self.t[:, :L]\n",
        "\n",
        "\n",
        "class ExponentialModulation(OptimModule):\n",
        "    \"\"\"The window function applied to the output of the (MLP) filter function.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model,\n",
        "        fast_decay_pct=0.3,\n",
        "        slow_decay_pct=1.5,\n",
        "        target=1e-2,\n",
        "        modulation_lr=0.0,\n",
        "        modulate: bool=True,\n",
        "        shift: float = 0.05,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.modulate = modulate\n",
        "        self.shift = shift\n",
        "        max_decay = math.log(target) / fast_decay_pct\n",
        "        min_decay = math.log(target) / slow_decay_pct\n",
        "        deltas = torch.linspace(min_decay, max_decay, d_model)[None, None]\n",
        "        self.register(\"deltas\", deltas, lr=modulation_lr)\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        if self.modulate:\n",
        "            decay = torch.exp(-t * self.deltas.abs())\n",
        "            x = x * (decay + self.shift)\n",
        "        return x\n",
        "\n",
        "\n",
        "class HyenaFilter(OptimModule):\n",
        "    def __init__(\n",
        "            self,\n",
        "            d_model,\n",
        "            emb_dim=3, # dim of input to MLP, augments with positional encoding\n",
        "            order=16, # width of the implicit MLP\n",
        "            fused_fft_conv=False,\n",
        "            seq_len=1024,\n",
        "            lr=1e-3,\n",
        "            lr_pos_emb=1e-5,\n",
        "            dropout=0.0,\n",
        "            w=1, # frequency of periodic activations\n",
        "            wd=0, # weight decay of kernel parameters\n",
        "            bias=True,\n",
        "            num_inner_mlps=2,\n",
        "            normalized=False,\n",
        "            **kwargs\n",
        "        ):\n",
        "        \"\"\"\n",
        "        Implicit long filter with modulation.\n",
        "\n",
        "        Args:\n",
        "            d_model: number of channels in the input\n",
        "            emb_dim: dimension of the positional encoding (`emb_dim` - 1) // 2 is the number of bands\n",
        "            order: width of the FFN\n",
        "            num_inner_mlps: number of inner linear layers inside filter MLP\n",
        "\n",
        "        Note:\n",
        "            filter_dropout is not implemented\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.use_bias = bias\n",
        "        self.fused_fft_conv = fused_fft_conv\n",
        "        self.bias = nn.Parameter(torch.randn(self.d_model))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        act = Sin(dim=order, w=w)\n",
        "        self.emb_dim = emb_dim\n",
        "        assert emb_dim % 2 != 0 and emb_dim >= 3, \"emb_dim must be odd and greater or equal to 3 (time, sine and cosine)\"\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        self.pos_emb = PositionalEmbedding(emb_dim, seq_len, lr_pos_emb)\n",
        "\n",
        "        self.implicit_filter = nn.Sequential(\n",
        "            nn.Linear(emb_dim, order),\n",
        "            act,\n",
        "        )\n",
        "        for i in range(num_inner_mlps):\n",
        "            self.implicit_filter.append(nn.Linear(order, order))\n",
        "            self.implicit_filter.append(act)\n",
        "\n",
        "        self.implicit_filter.append(nn.Linear(order, d_model, bias=False))\n",
        "\n",
        "        self.modulation = ExponentialModulation(d_model, **kwargs)\n",
        "\n",
        "        self.normalized = normalized\n",
        "        for c in self.implicit_filter.children():\n",
        "            for name, v in c.state_dict().items():\n",
        "                optim = {\"weight_decay\": wd, \"lr\": lr}\n",
        "                setattr(getattr(c, name), \"_optim\", optim)\n",
        "\n",
        "    def filter(self, L, *args, **kwargs):\n",
        "        z, t = self.pos_emb(L)\n",
        "        h = self.implicit_filter(z)\n",
        "        h = self.modulation(t, h)\n",
        "        return h\n",
        "\n",
        "    def forward(self, x, L, k=None, bias=None, *args, **kwargs):\n",
        "        if k is None: k = self.filter(L)\n",
        "\n",
        "        # Ensure compatibility with filters that return a tuple\n",
        "        k = k[0] if type(k) is tuple else k\n",
        "\n",
        "        y = fftconv(x, k, bias)\n",
        "        return y\n",
        "\n",
        "\n",
        "class HyenaOperator(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            d_model,\n",
        "            l_max,\n",
        "            order=2,\n",
        "            filter_order=64,\n",
        "            dropout=0.0,\n",
        "            filter_dropout=0.0,\n",
        "            **filter_args,\n",
        "        ):\n",
        "        r\"\"\"\n",
        "        Hyena operator described in the paper https://arxiv.org/pdf/2302.10866.pdf\n",
        "\n",
        "        Args:\n",
        "            d_model (int): Dimension of the input and output embeddings (width of the layer)\n",
        "            l_max: (int): Maximum input sequence length. Defaults to None\n",
        "            order: (int): Depth of the Hyena recurrence. Defaults to 2\n",
        "            dropout: (float): Dropout probability. Defaults to 0.0\n",
        "            filter_dropout: (float): Dropout probability for the filter. Defaults to 0.0\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.l_max = l_max\n",
        "        self.order = order\n",
        "        inner_width = d_model * (order + 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.in_proj = nn.Linear(d_model, inner_width)\n",
        "        self.out_proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.short_filter = nn.Conv1d(\n",
        "            inner_width,\n",
        "            inner_width,\n",
        "            3,\n",
        "            padding=2,\n",
        "            groups=inner_width\n",
        "        )\n",
        "        self.filter_fn = HyenaFilter(\n",
        "            d_model * (order - 1),\n",
        "            order=filter_order,\n",
        "            seq_len=l_max,\n",
        "            channels=1,\n",
        "            dropout=filter_dropout,\n",
        "            **filter_args\n",
        "        )\n",
        "\n",
        "    def forward(self, u, *args, **kwargs):\n",
        "        l = u.size(-2)\n",
        "        l_filter = min(l, self.l_max)\n",
        "        u = self.in_proj(u)\n",
        "        u = rearrange(u, 'b l d -> b d l')\n",
        "\n",
        "        uc = self.short_filter(u)[...,:l_filter]\n",
        "        *x, v = uc.split(self.d_model, dim=1)\n",
        "\n",
        "        k = self.filter_fn.filter(l_filter)[0]\n",
        "        k = rearrange(k, 'l (o d) -> o d l', o=self.order - 1)\n",
        "        bias = rearrange(self.filter_fn.bias, '(o d) -> o d', o=self.order - 1)\n",
        "\n",
        "        for o, x_i in enumerate(reversed(x[1:])):\n",
        "            v = self.dropout(v * x_i)\n",
        "            v = self.filter_fn(v, l_filter, k=k[o], bias=bias[o])\n",
        "\n",
        "        y = rearrange(v * x[0], 'b d l -> b l d')\n",
        "\n",
        "        y = self.out_proj(y)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MLP layer\n",
        "\n",
        "\"\"\"\n",
        "The MLP layer after the mixer layer (HyenaOperator).\n",
        "\"\"\"\n",
        "\n",
        "class Mlp(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, activation=F.gelu,\n",
        "                 return_residual=False, device=None, dtype=None):\n",
        "        \"\"\"\n",
        "        From https://github.com/HazyResearch/flash-attention/blob/main/flash_attn/modules/mlp.py\n",
        "        \"\"\"\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.return_residual = return_residual\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features, **factory_kwargs)\n",
        "        self.activation = activation\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features, **factory_kwargs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.fc1(x)\n",
        "        y = self.activation(y)\n",
        "        y = self.fc2(y)\n",
        "        return y if not self.return_residual else (y, x)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_1nNIXfxVg0M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Block layer (Hyena + MLP layers)\n",
        "\n",
        "\"\"\"\n",
        "A block consists of a Mixer layer (Hyena or attention), and a MLP layer.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class LinearResidual(nn.Linear):\n",
        "    \"\"\"Wrap nn.Linear to return the residual as well. For compatibility with FusedDense.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        return super().forward(input), input\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, mixer_cls=None, mlp_cls=None, norm_cls=nn.LayerNorm,\n",
        "                 dropout_cls=nn.Dropout, prenorm=True, resid_dropout1=0., resid_dropout2=0.,\n",
        "                 drop_path1=0., drop_path2=0.,\n",
        "                 return_residual=False,\n",
        "                 residual_in_fp32=False):\n",
        "        \"\"\"\n",
        "        From https://github.com/HazyResearch/flash-attention/blob/main/flash_attn/modules/block.py\n",
        "        For prenorm=True, this Block has a slightly different structure compared to a regular\n",
        "        prenorm Transformer block.\n",
        "        The standard block is: LN -> MHA -> Dropout -> Add -> LN -> MLP -> Dropout -> Add.\n",
        "        [Ref: https://arxiv.org/abs/2002.04745]\n",
        "        Here we have: Dropout -> Add -> LN -> MHA -> Dropout -> Add -> LN -> MLP, returning both\n",
        "        the hidden_states (output of the MLP) and the residual.\n",
        "        This is for performance reasons, as we can fuse the dropout, add and LayerNorm.\n",
        "        The residual needs to be provided (except for the very first block).\n",
        "        For prenorm=False, this Block has the same structure as a regular postnorm Transformer\n",
        "        block: MHA -> Dropout -> Add -> LN -> MLP -> Dropout -> Add -> LN.\n",
        "        return_residual: whether each of the sub-layers (mixer and mlp) will return the residual.\n",
        "        This is for performance reason: for post-norm architecture, returning the input allows us\n",
        "        to fuse the backward of nn.Linear with the residual connection.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.prenorm = prenorm\n",
        "        self.return_residual = return_residual\n",
        "        self.residual_in_fp32 = residual_in_fp32\n",
        "        if self.residual_in_fp32:\n",
        "            assert self.prenorm, 'residual_in_fp32 is only compatible with prenorm=True'\n",
        "        if mixer_cls is None:\n",
        "            mixer_cls = partial(MHA, num_heads=dim // 64)\n",
        "        if mlp_cls is None:\n",
        "            mlp_cls = partial(Mlp, hidden_features=4 * dim)\n",
        "        self.mixer = mixer_cls()\n",
        "        self.dropout1 = dropout_cls(resid_dropout1)\n",
        "        self.drop_path1 = StochasticDepth(drop_path1, mode='row')\n",
        "        self.norm1 = norm_cls(dim)\n",
        "        self.mlp = mlp_cls(dim)\n",
        "        if not isinstance(self.mlp, nn.Identity):\n",
        "            self.dropout2 = dropout_cls(resid_dropout2)\n",
        "            self.drop_path2 = StochasticDepth(drop_path2, mode='row')\n",
        "            self.norm2 = norm_cls(dim)\n",
        "\n",
        "    def forward(self, hidden_states, residual = None,\n",
        "                mixer_subset=None, mixer_kwargs=None):\n",
        "        r\"\"\"Pass the input through the encoder layer.\n",
        "        Args:\n",
        "            hidden_states: the sequence to the encoder layer (required).\n",
        "            residual: if postnorm, residual=None, If prenorm, hidden_states = Attn/MLP(LN(residual))\n",
        "            mixer_subset: for cross-attention only. If not None, will take a subset of x\n",
        "                before applying the query projection. Useful for e.g., ViT where we only care\n",
        "                about the CLS token in the last layer.\n",
        "        \"\"\"\n",
        "        if self.prenorm:\n",
        "            dropped = self.drop_path1(self.dropout1(hidden_states))\n",
        "            residual = (dropped + residual) if residual is not None else dropped\n",
        "            hidden_states = self.norm1(residual.to(dtype=self.norm1.weight.dtype))\n",
        "            if self.residual_in_fp32:\n",
        "                residual = residual.to(torch.float32)\n",
        "            if mixer_kwargs is None:\n",
        "                mixer_kwargs = {}\n",
        "            if mixer_subset is not None:\n",
        "                mixer_kwargs['mixer_subset'] = mixer_subset\n",
        "            hidden_states = self.mixer(hidden_states, **mixer_kwargs)\n",
        "            if mixer_subset is not None:\n",
        "                residual = residual[:, mixer_subset]\n",
        "            if not isinstance(self.mlp, nn.Identity):\n",
        "                dropped = self.drop_path2(self.dropout2(hidden_states))\n",
        "                residual = (dropped + residual) if residual is not None else dropped\n",
        "                hidden_states = self.norm2(residual.to(dtype=self.norm2.weight.dtype))\n",
        "                if self.residual_in_fp32:\n",
        "                    residual = residual.to(torch.float32)\n",
        "\n",
        "                hidden_states = self.mlp(hidden_states)\n",
        "            return hidden_states, residual\n",
        "        else:\n",
        "            assert residual is None\n",
        "            mixer_out = self.mixer(\n",
        "                hidden_states, **(mixer_kwargs if mixer_kwargs is not None else {})\n",
        "            )\n",
        "            if self.return_residual:  # mixer out is actually a pair here\n",
        "                mixer_out, hidden_states = mixer_out\n",
        "\n",
        "            hidden_states = self.norm1((self.drop_path1(self.dropout1(mixer_out))\n",
        "                                        + hidden_states).to(dtype=self.norm1.weight.dtype))\n",
        "\n",
        "            if not isinstance(self.mlp, nn.Identity):\n",
        "                mlp_out = self.mlp(hidden_states)\n",
        "                if self.return_residual:  # mlp out is actually a pair here\n",
        "                    mlp_out, hidden_states = mlp_out\n",
        "\n",
        "                hidden_states = self.norm2((self.drop_path2(self.dropout2(mlp_out))\n",
        "                                            + hidden_states).to(dtype=self.norm2.weight.dtype))\n",
        "\n",
        "            return hidden_states\n",
        "\n",
        "def create_mixer_cls(layer=None,\n",
        "                     attn_layer_idx=None, attn_cfg=None, layer_idx=None,\n",
        "                     device=None, dtype=None):\n",
        "    factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "    if attn_layer_idx is not None and layer_idx in attn_layer_idx:\n",
        "        causal = True if attn_cfg is None else attn_cfg.pop('causal', True)\n",
        "\n",
        "        mha_cls = MHA\n",
        "\n",
        "        mixer_cls = partial(mha_cls, causal=causal, layer_idx=layer_idx,\n",
        "                            **(attn_cfg if attn_cfg is not None else {}),**factory_kwargs)\n",
        "    else:\n",
        "        # mixer_cls = instantiate(registry.layer, layer, partial=True, layer_idx=layer_idx, **factory_kwargs)\n",
        "\n",
        "        mixer_cls = partial(HyenaOperator, **layer)\n",
        "\n",
        "    return mixer_cls\n",
        "\n",
        "def create_mlp_cls(d_model, d_inner=None, device=None, dtype=None):\n",
        "    factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "    inner_dim = d_inner if d_inner is not None else 4 * d_model\n",
        "\n",
        "    mlp_cls = partial(Mlp, hidden_features=inner_dim,\n",
        "                          activation=partial(F.gelu, approximate='tanh'), **factory_kwargs)\n",
        "\n",
        "    return mlp_cls\n",
        "\n",
        "\n",
        "def create_block(d_model, d_inner=None,\n",
        "                 layer=None, attn_layer_idx=None,\n",
        "                 attn_cfg=None, layer_norm_epsilon=1e-5,\n",
        "                 resid_dropout1=0.0, resid_dropout2=0.0, residual_in_fp32=False,\n",
        "                 layer_idx=None,\n",
        "                 device=None, dtype=None):\n",
        "    factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "    mixer_cls = create_mixer_cls(layer=layer,\n",
        "                                 attn_layer_idx=attn_layer_idx,\n",
        "                                 attn_cfg=attn_cfg, layer_idx=layer_idx,\n",
        "                                 **factory_kwargs)\n",
        "    mlp_cls = create_mlp_cls(d_model, d_inner=d_inner,\n",
        "                             **factory_kwargs)\n",
        "    norm_cls = partial(nn.LayerNorm, eps=layer_norm_epsilon, **factory_kwargs)\n",
        "    block = Block(d_model, mixer_cls, mlp_cls, norm_cls=norm_cls,\n",
        "                  prenorm=True, resid_dropout1=resid_dropout1, resid_dropout2=resid_dropout2,residual_in_fp32=residual_in_fp32)\n",
        "    block.layer_idx = layer_idx\n",
        "    return block\n",
        "\n",
        "\n",
        "# https://github.com/huggingface/transformers/blob/c28d04e9e252a1a099944e325685f14d242ecdcd/src/transformers/models/gpt2/modeling_gpt2.py#L454\n",
        "def _init_weights(module, n_layer, initializer_range=0.02, rescale_prenorm_residual=True,\n",
        "                  glu_act=False):\n",
        "    if isinstance(module, nn.Linear):\n",
        "        nn.init.normal_(module.weight, std=initializer_range)\n",
        "        if module.bias is not None:\n",
        "            nn.init.zeros_(module.bias)\n",
        "    elif isinstance(module, nn.Embedding):\n",
        "        nn.init.normal_(module.weight, std=initializer_range)\n",
        "\n",
        "    if rescale_prenorm_residual:\n",
        "        # Reinitialize selected weights subject to the OpenAI GPT-2 Paper Scheme:\n",
        "        #   > A modified initialization which accounts for the accumulation on the residual path with model depth. Scale\n",
        "        #   > the weights of residual layers at initialization by a factor of 1/âˆšN where N is the # of residual layers.\n",
        "        #   >   -- GPT-2 :: https://openai.com/blog/better-language-models/\n",
        "        #\n",
        "        # Reference (Megatron-LM): https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/model/gpt_model.py\n",
        "        for name, p in module.named_parameters():\n",
        "            if name in [\"out_proj.weight\", \"fc2.weight\"]:\n",
        "                # Special Scaled Initialization --> There are 2 Layer Norms per Transformer Block\n",
        "                nn.init.normal_(p, mean=0.0, std=initializer_range / math.sqrt(2 * n_layer))\n",
        "            # If using GLU activation for now, we scale the std by 2\n",
        "            elif name in [\"output_linear.0.weight\"]:\n",
        "                # Special Scaled Initialization --> There are 2 Layer Norms per Transformer Block\n",
        "                if not glu_act:\n",
        "                    nn.init.normal_(p, mean=0.0, std=initializer_range / math.sqrt(2 * n_layer))\n",
        "                else:\n",
        "                    out_features = p.shape[0]\n",
        "                    # Multiplying the first half of the matrix by 2 since sigmoid scales it down by 0.5\n",
        "                    # on average.\n",
        "                    nn.init.normal_(p[:out_features // 2], mean=0.0, std=initializer_range / math.sqrt(2 * n_layer) * 2)\n",
        "\n"
      ],
      "metadata": {
        "id": "cJZaIEqbR2KH",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Backbone model (stack of blocks)\n",
        "\n",
        "\"\"\"\n",
        "A backbone model consists of a stack of blocks. If you use attention, then\n",
        "positional embeddings are included. When using Hyena, then the pos emb\n",
        "revert to doing nothing.\n",
        "\"\"\"\n",
        "\n",
        "class GPT2Embeddings(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_dim, vocab_size, max_position_embeddings, padding_idx=None,\n",
        "                 word_embed_proj_dim=None, device=None, dtype=None):\n",
        "        \"\"\"\n",
        "            If max_position_embeddings <= 0, there's no position embeddings\n",
        "            If word_embe_proj_dim is not None (e.g., OPT-350m), we embed to that dimension\n",
        "                the project up to embed_dim\n",
        "        \"\"\"\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        super().__init__()\n",
        "        if word_embed_proj_dim is None:\n",
        "            self.word_embeddings = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx,\n",
        "                                                **factory_kwargs)\n",
        "            self.project_in = None\n",
        "        else:\n",
        "            self.word_embeddings = nn.Embedding(vocab_size, word_embed_proj_dim,\n",
        "                                                padding_idx=padding_idx, **factory_kwargs)\n",
        "            self.project_in = nn.Linear(word_embed_proj_dim, embed_dim, bias=False,\n",
        "                                        **factory_kwargs)\n",
        "        self.max_position_embeddings = max_position_embeddings\n",
        "        if self.max_position_embeddings > 0:\n",
        "            self.position_embeddings = nn.Embedding(max_position_embeddings, embed_dim,\n",
        "                                                    **factory_kwargs)\n",
        "\n",
        "    def forward(self, input_ids, position_ids=None):\n",
        "        \"\"\"\n",
        "            input_ids: (batch, seqlen)\n",
        "            position_ids: (batch, seqlen)\n",
        "        \"\"\"\n",
        "        batch_size, seqlen = input_ids.shape\n",
        "        embeddings = self.word_embeddings(input_ids)\n",
        "        if self.project_in is not None:\n",
        "            embeddings = self.project_in(embeddings)\n",
        "        if self.max_position_embeddings > 0:\n",
        "            if position_ids is None:\n",
        "                position_ids = torch.arange(seqlen, dtype=torch.long, device=input_ids.device)\n",
        "            position_embeddings = self.position_embeddings(position_ids)\n",
        "            embeddings = embeddings + position_embeddings\n",
        "        return embeddings\n",
        "\n",
        "class LMBackbone(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, n_layer: int, d_inner: int, vocab_size: int,\n",
        "                 process_group=None, layer=None,\n",
        "                 attn_layer_idx=None, attn_cfg=None, max_position_embeddings=0,\n",
        "                 resid_dropout: float = 0.0, embed_dropout: float = 0.1,\n",
        "                 layer_norm_epsilon: float = 1e-5, initializer_cfg=None,residual_in_fp32=False,\n",
        "                 device=None, dtype=None, **kwargs) -> None:\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        super().__init__()\n",
        "        self.process_group = process_group\n",
        "        self.residual_in_fp32 = residual_in_fp32\n",
        "        # note max_position_embeddings is 0 for Hyena, and therefore isn't used\n",
        "        self.embeddings = GPT2Embeddings(d_model, vocab_size, max_position_embeddings,\n",
        "                                             **factory_kwargs)\n",
        "\n",
        "        self.layers = nn.ModuleList([create_block(\n",
        "            d_model, d_inner=d_inner,\n",
        "            layer=layer, attn_layer_idx=attn_layer_idx,\n",
        "            attn_cfg=attn_cfg, layer_norm_epsilon=layer_norm_epsilon,\n",
        "            resid_dropout1=embed_dropout if i == 0 else resid_dropout,\n",
        "            resid_dropout2=resid_dropout, residual_in_fp32=residual_in_fp32,layer_idx=i,\n",
        "            **factory_kwargs,\n",
        "        ) for i in range(n_layer)])\n",
        "\n",
        "        self.drop_f = nn.Dropout(resid_dropout)\n",
        "        self.ln_f = nn.LayerNorm(d_model, eps=layer_norm_epsilon, **factory_kwargs)\n",
        "\n",
        "        self.apply(partial(_init_weights, n_layer=n_layer,\n",
        "                           **(initializer_cfg if initializer_cfg is not None else {})))\n",
        "\n",
        "    def forward(self, input_ids, position_ids=None):\n",
        "        hidden_states = self.embeddings(input_ids, position_ids=position_ids,)\n",
        "        residual = None\n",
        "\n",
        "        for layer in self.layers:\n",
        "            hidden_states, residual = layer(hidden_states, residual)\n",
        "\n",
        "        dropped = self.drop_f(hidden_states)\n",
        "        residual = (dropped + residual) if residual is not None else dropped\n",
        "        hidden_states = self.ln_f(residual.to(dtype=self.ln_f.weight.dtype))\n",
        "\n",
        "        return hidden_states"
      ],
      "metadata": {
        "id": "4UTkl8mYR38E",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Decoder head layer\n",
        "\n",
        "\"\"\"\n",
        "adapted decode head for binary readmission classification\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class SequenceDecoder(nn.Module):\n",
        "    def __init__(\n",
        "        self, d_model, d_output=None, l_output=None, use_lengths=False, mode=\"last\"\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_transform = nn.Identity() if d_output is None else nn.Linear(d_model, d_output)\n",
        "\n",
        "        if l_output is None:\n",
        "            self.l_output = None\n",
        "            self.squeeze = False\n",
        "        elif l_output == 0:\n",
        "            # Equivalent to getting an output of length 1 and then squeezing\n",
        "            self.l_output = 1\n",
        "            self.squeeze = True\n",
        "        else:\n",
        "            assert l_output > 0\n",
        "            self.l_output = l_output\n",
        "            self.squeeze = False\n",
        "\n",
        "        self.use_lengths = use_lengths\n",
        "        self.mode = mode\n",
        "\n",
        "        if mode == 'ragged':\n",
        "            assert not use_lengths\n",
        "\n",
        "    def forward(self, x, state=None, lengths=None, l_output=None):\n",
        "        \"\"\"\n",
        "        x: (n_batch, l_seq, d_model)\n",
        "        Returns: (n_batch, l_output, d_output)\n",
        "        \"\"\"\n",
        "\n",
        "        if self.l_output is None:\n",
        "            if l_output is not None:\n",
        "                assert isinstance(l_output, int)  # Override by pass in\n",
        "            else:\n",
        "                # Grab entire output\n",
        "                l_output = x.size(-2)\n",
        "            squeeze = False\n",
        "        else:\n",
        "            l_output = self.l_output\n",
        "            squeeze = self.squeeze\n",
        "\n",
        "        if self.mode == \"last\":\n",
        "            restrict = lambda x: x[..., -l_output:, :]\n",
        "        elif self.mode == \"first\":\n",
        "            restrict = lambda x: x[..., :l_output, :]\n",
        "        elif self.mode == \"pool\":\n",
        "            restrict = lambda x: (\n",
        "                torch.cumsum(x, dim=-2)\n",
        "                / torch.arange(\n",
        "                    1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
        "                ).unsqueeze(-1)\n",
        "            )[..., -l_output:, :]\n",
        "\n",
        "            def restrict(x):\n",
        "                L = x.size(-2)\n",
        "                s = x.sum(dim=-2, keepdim=True)\n",
        "                if l_output > 1:\n",
        "                    c = torch.cumsum(x[..., -(l_output - 1) :, :].flip(-2), dim=-2)\n",
        "                    c = F.pad(c, (0, 0, 1, 0))\n",
        "                    s = s - c  # (B, l_output, D)\n",
        "                    s = s.flip(-2)\n",
        "                denom = torch.arange(\n",
        "                    L - l_output + 1, L + 1, dtype=x.dtype, device=x.device\n",
        "                )\n",
        "                s = s / denom\n",
        "                return s\n",
        "\n",
        "        elif self.mode == \"sum\":\n",
        "            restrict = lambda x: torch.cumsum(x, dim=-2)[..., -l_output:, :]\n",
        "            # TODO use same restrict function as pool case\n",
        "        elif self.mode == 'ragged':\n",
        "            assert lengths is not None, \"lengths must be provided for ragged mode\"\n",
        "            # remove any additional padding (beyond max length of any sequence in the batch)\n",
        "            restrict = lambda x: x[..., : max(lengths), :]\n",
        "        else:\n",
        "            raise NotImplementedError(\n",
        "                \"Mode must be ['last' | 'first' | 'pool' | 'sum']\"\n",
        "            )\n",
        "\n",
        "        # Restrict to actual length of sequence\n",
        "        if self.use_lengths:\n",
        "            assert lengths is not None\n",
        "            x = torch.stack(\n",
        "                [\n",
        "                    restrict(out[..., :length, :])\n",
        "                    for out, length in zip(torch.unbind(x, dim=0), lengths)\n",
        "                ],\n",
        "                dim=0,\n",
        "            )\n",
        "        else:\n",
        "            x = restrict(x)\n",
        "\n",
        "        if squeeze:\n",
        "            assert x.size(-2) == 1\n",
        "            x = x.squeeze(-2)\n",
        "\n",
        "        x = self.output_transform(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def step(self, x, state=None):\n",
        "        # Ignore all length logic\n",
        "        return self.output_transform(x)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "BmKX9q1qWydM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model (backbone + head)\n",
        "\n",
        "\"\"\"\n",
        "Putting it all together, the model consists of a backbone model\n",
        "and a decoder head\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class ClinicalHeyna(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, n_layer: int, d_inner: int, vocab_size: int,\n",
        "                 layer=None, attn_layer_idx=None, attn_cfg=None, max_position_embeddings=0,\n",
        "                 resid_dropout: float = 0.0, embed_dropout: float = 0.1,\n",
        "                 layer_norm_epsilon: float = 1e-5, initializer_cfg=None,residual_in_fp32=False,\n",
        "                 pad_vocab_size_multiple: int = 1, use_head=None, n_classes: int = 2,\n",
        "                 device=None, dtype=None, **kwargs) -> None:\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        super().__init__()\n",
        "        if vocab_size % pad_vocab_size_multiple != 0:\n",
        "            vocab_size += pad_vocab_size_multiple - (vocab_size % pad_vocab_size_multiple)\n",
        "\n",
        "        self.use_head = use_head\n",
        "\n",
        "        # check if layer (config) has d_model (HF code differs from main Safari code)\n",
        "        if 'd_model' not in layer:\n",
        "            layer['d_model'] = d_model\n",
        "\n",
        "        self.backbone = LMBackbone(\n",
        "            d_model=d_model, n_layer=n_layer, d_inner=d_inner, vocab_size=vocab_size,\n",
        "            layer=layer, attn_layer_idx=attn_layer_idx, attn_cfg=attn_cfg,\n",
        "            max_position_embeddings=max_position_embeddings,\n",
        "            resid_dropout=resid_dropout, embed_dropout=embed_dropout,\n",
        "            layer_norm_epsilon=layer_norm_epsilon,\n",
        "            initializer_cfg=initializer_cfg, residual_in_fp32=residual_in_fp32,\n",
        "            **factory_kwargs, **kwargs\n",
        "        )\n",
        "\n",
        "        # we only need a head if doing classification, otherwise we'll use the\n",
        "        # hidden states as embeddings\n",
        "        if self.use_head == 'classification':\n",
        "            self.head = SequenceDecoder(d_model=d_model, d_output=n_classes, l_output=0, mode='pool')\n",
        "        if self.use_head == 'generation':\n",
        "            self.head = SequenceDecoder(d_model=d_model, d_output=vocab_size, l_output=0, mode='pool')\n",
        "        # Initialize weights and apply final processing\n",
        "        self.apply(partial(_init_weights, n_layer=n_layer,\n",
        "                           **(initializer_cfg if initializer_cfg is not None else {})))\n",
        "\n",
        "        # if self.use_head:\n",
        "        #     self.tie_weights()\n",
        "\n",
        "    # def tie_weights(self):\n",
        "    #     self.head.weight = self.backbone.embeddings.word_embeddings.weight\n",
        "\n",
        "    def forward(self, input_ids, position_ids=None, state=None): # state for the repo interface\n",
        "        hidden_states = self.backbone(input_ids, position_ids=position_ids)\n",
        "        return self.head(hidden_states)"
      ],
      "metadata": {
        "id": "llZ46qSfXBhS",
        "cellView": "form"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data pipeline"
      ],
      "metadata": {
        "id": "ZHXgGpmcsGVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tokenizer\n",
        "\n",
        "from transformers import GPT2Tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
      ],
      "metadata": {
        "id": "yntLs82VsIrC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Utility\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def save_model(model,path='/content/trained_model.pt'):\n",
        "  torch.save(model.state_dict(), path)\n",
        "\n",
        "def load_model(model,state_dict,path='/content/trained_model.pt'):\n",
        "  model.load_state_dict(torch.load(path))\n",
        "\n",
        "def print_statistics(df_input):\n",
        "  l = list(df_input['TEXT'])\n",
        "  lenl = [len(tokenizer(i)['input_ids']) for i in l]\n",
        "  mean = sum(lenl)/len(lenl)\n",
        "\n",
        "  print(f'dataset size: {len(lenl)}')\n",
        "  print(f'maximum length: {max(lenl)}')\n",
        "  print(f'mean: {mean}')\n",
        "  print(f'std_dev: {(sum([((x - mean) ** 2) for x in lenl]) / len(lenl))**0.5 }')\n",
        "  return l\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oG175nQ1EEQN"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Utility: Load Pre-trained Weights (Experiment 1)\n",
        "\n",
        "def load_pretrained_model():\n",
        "  model_cfg = '/content/drive/MyDrive/heyna_data/heyna_checkpoint/hyena_small_150b.yaml'\n",
        "  model_ckpt = '/content/drive/MyDrive/heyna_data/heyna_checkpoint/hyena_small_150b_tok.ckpt'\n",
        "\n",
        "  loaded_ckpt = torch.load(model_ckpt,map_location=torch.device('cpu'))\n",
        "  config = yaml.load(open(model_cfg, 'r'), Loader=yaml.FullLoader)['model_config']\n",
        "  generation_model = ClinicalHeyna(**config, use_head='generation')\n",
        "\n",
        "  # binary classification model with the same config to be used later for readmission\n",
        "  classification_model = ClinicalHeyna(**config, use_head='classification', n_classes=2)\n",
        "  generation_dict = generation_model.state_dict()\n",
        "\n",
        "  # ******* load THE PILE 150b pre-trained weights (generation) *****\n",
        "  for key, value in generation_dict.items():\n",
        "    if key in['head.output_transform.bias']:\n",
        "      continue\n",
        "    if key in ['head.output_transform.weight']:\n",
        "      generation_dict[key] = loaded_ckpt['lm_head.weight']\n",
        "    else:\n",
        "      generation_dict[key] = loaded_ckpt[key]\n",
        "\n",
        "  generation_model.load_state_dict(generation_dict)\n",
        "  return generation_model, classification_model\n"
      ],
      "metadata": {
        "id": "9_PcUlcQaxB3",
        "cellView": "form"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Finetuning data inspection\n",
        "train = pd.read_csv('/content/drive/MyDrive/heyna_data/heyna_finetune_data/discharge/train.csv')\n",
        "val = pd.read_csv('/content/drive/MyDrive/heyna_data/heyna_finetune_data/discharge/val.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/heyna_data/heyna_finetune_data/discharge/test.csv')\n",
        "train3 = pd.read_csv('/content/drive/MyDrive/heyna_data/heyna_finetune_data/3days/train.csv')\n",
        "val3 = pd.read_csv('/content/drive/MyDrive/heyna_data/heyna_finetune_data/3days/val.csv')\n",
        "test3 = pd.read_csv('/content/drive/MyDrive/heyna_data/heyna_finetune_data/3days/test.csv')\n",
        "test2 = pd.read_csv('/content/drive/MyDrive/heyna_data/heyna_finetune_data/2days/test.csv')\n",
        "\n",
        "train_discharge = pd.concat([train,val],ignore_index=True)\n",
        "test_discharge = test\n",
        "train_3 = pd.concat([train3,val3],ignore_index=True)\n",
        "test_3 = test3\n",
        "test_2 = test2"
      ],
      "metadata": {
        "id": "dTSfdVFGjJg7",
        "cellView": "form"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = print_statistics(test_discharge)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXvqL5Z9NbTE",
        "outputId": "1a64f29f-84d7-4258-9a40-e164ee89128b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset size: 3063\n",
            "maximum length: 1360\n",
            "mean: 469.97486124714334\n",
            "std_dev: 158.6875952230489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clinical Note dataset\n",
        "\n",
        "class ClinicalNoteDataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        file_path = '/content/drive/MyDrive/heyna_data/clinical_sentences_pretrain.txt',\n",
        "        d_output=2,\n",
        "        max_length=5383, # maximum allowed sequence length in the training subset\n",
        "        tokenizer=None,\n",
        "        training_size=359809\n",
        "    ):\n",
        "\n",
        "        ''' A next token predition dataset. For each text in file, we use the last token in text as label, and the rest of sequence as input'''\n",
        "\n",
        "        self.d_output = d_output\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        with open(file_path, 'r') as file:\n",
        "          notes = file.read().split('\\n\\n')\n",
        "        notes = [note.strip() for note in notes][:training_size]\n",
        "        note_toks = [self.tokenizer(n)['input_ids'] for n in notes]\n",
        "\n",
        "        # generate training subset\n",
        "        note_toks = [n for n in note_toks if len(n) <= max_length]\n",
        "        l = [self.last_token(tok) for tok in note_toks]\n",
        "\n",
        "        self.input_ids = torch.tensor([i[0] + [50257]*(max_length-len(i[0])) for i in l])\n",
        "        self.targets = torch.tensor([i[1] for i in l])\n",
        "\n",
        "    def last_token(self,note_tok):\n",
        "      # return input sequence, last token\n",
        "      for i, ele in enumerate(reversed(note_tok)):\n",
        "        if ele != 50257:\n",
        "            idx = len(note_tok)-i-1\n",
        "            return note_tok[:idx], ele\n",
        "      return note_tok[:-1], 50257\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.input_ids.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.targets[idx]"
      ],
      "metadata": {
        "id": "embt6a0-oz3y",
        "cellView": "form"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Readmission dataset\n",
        "\n",
        "class ReadmissionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        split,\n",
        "        max_length=1362,\n",
        "        folder = 'discharge/', # early note or discharge\n",
        "        d_output=2, # default binary classification\n",
        "        tokenizer=None,\n",
        "        set_size=53567\n",
        "    ):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.d_output = d_output  # needed for decoder to grab\n",
        "        folder = '/content/drive/MyDrive/heyna_data/heyna_finetune_data/' + folder\n",
        "\n",
        "        if split == 'train':\n",
        "          train = pd.read_csv(folder + split + '.csv')\n",
        "          val = pd.read_csv(folder + 'val.csv')\n",
        "          data = pd.concat([train, val], ignore_index=True) # train = train + val; we don't use val for anything other than training\n",
        "        else:\n",
        "          data = pd.read_csv(folder + 'test.csv')\n",
        "\n",
        "        texts = list(data['TEXT'])[:set_size]\n",
        "        labels = list(data['Label'])[:set_size]\n",
        "\n",
        "        note_toks = [self.tokenizer(n,padding=\"max_length\",truncation=True, max_length=max_length)['input_ids'] for n in texts]\n",
        "        self.input_ids = torch.tensor(note_toks)\n",
        "        self.labels = torch.tensor(labels).type(torch.LongTensor)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.input_ids.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "k4w3A1XxsqnT",
        "cellView": "form"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = ReadmissionDataset(split='test',tokenizer=tokenizer,set_size=2)"
      ],
      "metadata": {
        "id": "kRbLFWgg7RoB"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret.labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAIWvdT37WRL",
        "outputId": "8a5c9940-e083-4a2f-e663-b07ace05d033"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "ASyfELww-zr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Train and Test Loop\n",
        "\n",
        "def training(model, train_loader, optimizer, epoch, loss_fn, log_interval=10):\n",
        "    \"\"\"Training loop.\"\"\"\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "          print()\n",
        "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "              epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "              100. * batch_idx / len(train_loader), loss.item()))\n",
        "          print()\n",
        "\n",
        "def testing(model, test_loader, loss_fn):\n",
        "    \"\"\"Test loop.\"\"\"\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(tqdm(test_loader)):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += loss_fn(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            print(pred)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n"
      ],
      "metadata": {
        "id": "gip6RLA1kpJJ"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train on Note\n",
        "def train_on_note(model, max_length, training_size=359809, num_epochs=3):\n",
        "\n",
        "    # experiment settings:\n",
        "    batch_size = 1\n",
        "    learning_rate = 6e-4  # good default for Hyena\n",
        "    weight_decay = 0.1\n",
        "    n_classes = 2\n",
        "\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "    # clinical note set\n",
        "    cn_train = ClinicalNoteDataset(\n",
        "        max_length = max_length,\n",
        "        tokenizer=tokenizer,\n",
        "        training_size=training_size\n",
        "    )\n",
        "\n",
        "    cn_loader = DataLoader(cn_train, batch_size=batch_size, shuffle=True)\n",
        "    print(f'\\n Effective dataset size: {len(cn_loader.dataset)} \\n')\n",
        "\n",
        "    # loss function\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # create optimizer\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        print()\n",
        "        print()\n",
        "        print(f\"------------- start of epoch {epoch+1} ----------------\")\n",
        "        training(model, cn_loader, optimizer, epoch, loss_fn)\n",
        "        optimizer.step()\n",
        "        testing(model, cn_loader, loss_fn)\n",
        "        print()\n",
        "        print()"
      ],
      "metadata": {
        "id": "OBYFOn6WlF4y"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Finetune on Readmission\n",
        "def finetune_readmission(gmodel, cmodel, transfer_weight, max_length, train_size=53567, test_size=5541, num_epochs=5, early_or_discharge='discharge/'):\n",
        "\n",
        "    if transfer_weight:\n",
        "      # transfer weight from gmodel to cmodel\n",
        "      gdict = gmodel.state_dict()\n",
        "      cdict = cmodel.state_dict()\n",
        "\n",
        "      for key, value in cdict.items():\n",
        "        if key in['head.output_transform.bias','head.output_transform.weight']:\n",
        "          continue\n",
        "        else:\n",
        "          cdict[key] = gdict[key]\n",
        "      cmodel.load_state_dict(cdict)\n",
        "\n",
        "    # experiment settings:\n",
        "    batch_size = 1\n",
        "    learning_rate = 6e-4  # good default for Hyena\n",
        "    weight_decay = 0.1\n",
        "    n_classes = 2\n",
        "\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "    # clinical note set\n",
        "    re_train = ReadmissionDataset(\n",
        "        split='train',\n",
        "        max_length = max_length,\n",
        "        tokenizer=tokenizer,\n",
        "        folder=early_or_discharge,\n",
        "        set_size=train_size\n",
        "    )\n",
        "\n",
        "    re_test = ReadmissionDataset(\n",
        "        split='test',\n",
        "        max_length = max_length,\n",
        "        tokenizer=tokenizer,\n",
        "        folder=early_or_discharge,\n",
        "        set_size=test_size\n",
        "    )\n",
        "\n",
        "    re_train_loader = DataLoader(re_train, batch_size=batch_size, shuffle=True)\n",
        "    re_test_loader = DataLoader(re_test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # loss function\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # create optimizer\n",
        "    optimizer = optim.AdamW(cmodel.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    cmodel.to(device)\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        print()\n",
        "        print()\n",
        "        print(f\"------------- start of epoch {epoch+1} ----------------\")\n",
        "        training(cmodel, re_train_loader, optimizer, epoch, loss_fn)\n",
        "        testing(cmodel, re_test_loader, loss_fn)\n",
        "        optimizer.step()\n",
        "        print()\n",
        "        print()"
      ],
      "metadata": {
        "id": "vHbgIWH_XpTS"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "rBbEqzZn-3eP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Experiment 1 train\n",
        "gmodel, cmodel = load_pretrained_model()\n",
        "train_on_note(gmodel, max_length=2048,training_size=3,num_epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o36nprSV3ALN",
        "outputId": "e3798dc2-c13e-4381-dc5a-a2dcfe5bdd06"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Effective dataset size: 3 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "------------- start of epoch 1 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:10<00:20, 10.23s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 0 [0/3 (0%)]\tLoss: 2.886363\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:20<00:10, 10.12s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:29<00:00,  9.96s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:03<00:06,  3.13s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1106]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.94s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1106]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1106]])\n",
            "\n",
            "Test set: Average loss: 6.9167, Accuracy: 0/3 (0.00%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  5%|â–Œ         | 1/20 [00:39<12:25, 39.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 2 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:10<00:20, 10.01s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 1 [0/3 (0%)]\tLoss: 17.625233\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:20<00:10, 10.03s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:29<00:00,  9.78s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:03<00:07,  3.72s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:06<00:03,  3.21s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 4.9281, Accuracy: 2/3 (66.67%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 10%|â–ˆ         | 2/20 [01:18<11:47, 39.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 3 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:10<00:20, 10.12s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 2 [0/3 (0%)]\tLoss: 0.077192\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:20<00:10, 10.16s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:30<00:00, 10.00s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:03<00:06,  3.39s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:06<00:03,  3.09s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 4.4291, Accuracy: 2/3 (66.67%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 15%|â–ˆâ–Œ        | 3/20 [01:58<11:12, 39.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 4 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:10<00:20, 10.27s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 3 [0/3 (0%)]\tLoss: 0.023369\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:20<00:10, 10.14s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:30<00:00, 10.06s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:05,  2.83s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.82s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n",
            "\n",
            "Test set: Average loss: 1.2343, Accuracy: 1/3 (33.33%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|â–ˆâ–ˆ        | 4/20 [02:37<10:31, 39.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 5 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:09<00:19,  9.98s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 4 [0/3 (0%)]\tLoss: 1.268028\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:20<00:10, 10.01s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:29<00:00,  9.94s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:05,  2.99s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.88s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 0.7652, Accuracy: 2/3 (66.67%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 5/20 [03:16<09:49, 39.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 6 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:10<00:20, 10.09s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 5 [0/3 (0%)]\tLoss: 2.707928\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:20<00:10, 10.10s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:29<00:00,  9.87s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:03<00:06,  3.23s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:06<00:02,  2.97s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 0.7927, Accuracy: 2/3 (66.67%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [03:55<09:09, 39.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 7 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:10<00:20, 10.13s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 6 [0/3 (0%)]\tLoss: 0.029566\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:20<00:10, 10.13s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:30<00:00, 10.04s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:05,  2.81s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.79s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 0.4027, Accuracy: 2/3 (66.67%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [04:35<08:29, 39.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 8 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:10<00:20, 10.20s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 7 [0/3 (0%)]\tLoss: 4.140276\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:20<00:10, 10.14s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:30<00:00, 10.02s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:05,  2.85s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.77s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n",
            "\n",
            "Test set: Average loss: 2.3030, Accuracy: 1/3 (33.33%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [05:14<07:49, 39.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 9 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:10<00:20, 10.02s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 8 [0/3 (0%)]\tLoss: 0.911779\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:20<00:10, 10.02s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:29<00:00,  9.86s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:03<00:06,  3.18s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.93s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 1.5819, Accuracy: 2/3 (66.67%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [05:53<07:10, 39.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 10 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:10<00:20, 10.04s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 9 [0/3 (0%)]\tLoss: 2.422383\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:20<00:10, 10.43s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:30<00:00, 10.19s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:03<00:06,  3.33s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:06<00:03,  3.07s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n",
            "\n",
            "Test set: Average loss: 0.5222, Accuracy: 1/3 (33.33%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [06:33<06:34, 39.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 11 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:10<00:20, 10.09s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 10 [0/3 (0%)]\tLoss: 0.107847\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:20<00:10, 10.08s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:29<00:00,  9.75s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:03<00:07,  3.71s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:06<00:03,  3.15s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 0.4027, Accuracy: 3/3 (100.00%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [07:12<05:54, 39.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 12 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:12<00:24, 12.10s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 11 [0/3 (0%)]\tLoss: 0.460610\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:26<00:13, 13.26s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:36<00:00, 12.11s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:05,  2.76s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.75s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 0.5703, Accuracy: 2/3 (66.67%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [07:58<05:31, 41.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 13 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:09<00:18,  9.23s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 12 [0/3 (0%)]\tLoss: 0.018830\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:19<00:09,  9.73s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:29<00:00,  9.80s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:05,  2.76s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.75s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 0.7461, Accuracy: 2/3 (66.67%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [08:37<04:44, 40.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 14 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:09<00:19,  9.58s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 13 [0/3 (0%)]\tLoss: 2.015044\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:19<00:09,  9.92s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:30<00:00, 10.01s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:05,  2.89s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.83s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 0.2395, Accuracy: 3/3 (100.00%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [09:17<04:02, 40.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 15 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:09<00:18,  9.41s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 14 [0/3 (0%)]\tLoss: 0.306981\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:19<00:09,  9.93s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:29<00:00,  9.95s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:05,  2.81s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.80s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 0.3377, Accuracy: 3/3 (100.00%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [09:57<03:21, 40.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 16 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:09<00:18,  9.19s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 15 [0/3 (0%)]\tLoss: 0.356495\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:19<00:09,  9.75s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:29<00:00,  9.87s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:05,  2.80s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.79s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 0.1854, Accuracy: 3/3 (100.00%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [10:36<02:40, 40.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 17 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:09<00:18,  9.07s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 16 [0/3 (0%)]\tLoss: 0.068611\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:19<00:09,  9.62s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:29<00:00,  9.71s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:05,  2.77s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.93s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n",
            "\n",
            "Test set: Average loss: 0.2446, Accuracy: 3/3 (100.00%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [11:15<01:59, 39.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 18 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:11<00:22, 11.06s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 17 [0/3 (0%)]\tLoss: 0.031145\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:20<00:10, 10.22s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:30<00:00, 10.27s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:02<00:05,  2.72s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:06<00:03,  3.24s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 0.1657, Accuracy: 3/3 (100.00%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [11:56<01:20, 40.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 19 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:10<00:20, 10.18s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 18 [0/3 (0%)]\tLoss: 0.058332\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:22<00:11, 11.36s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:31<00:00, 10.47s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:03<00:07,  3.62s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:06<00:03,  3.16s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n",
            "\n",
            "Test set: Average loss: 0.1152, Accuracy: 3/3 (100.00%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [12:37<00:40, 40.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "------------- start of epoch 20 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:09<00:19,  9.98s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 19 [0/3 (0%)]\tLoss: 0.122589\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:19<00:09,  9.87s/it]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:29<00:00,  9.67s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:03<00:07,  3.79s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:06<00:03,  3.24s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[736]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13]])\n",
            "\n",
            "Test set: Average loss: 0.0943, Accuracy: 3/3 (100.00%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [13:17<00:00, 39.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Experiment 1 finetune\n",
        "finetune_readmission(gmodel, cmodel, transfer_weight=True, max_length=2048, train_size=1000, test_size=5, early_or_discharge='3days/',num_epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "ZJr7ZDr2bQq4",
        "outputId": "b59fe228-ddf7-451e-b6f5-c9b8084b885c"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "------------- start of epoch 1 ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/1000 [00:09<2:34:22,  9.27s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Epoch: 0 [0/1000 (0%)]\tLoss: 0.203086\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 2/1000 [00:28<4:00:02, 14.43s/it]\n",
            "  0%|          | 0/3 [00:28<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-166-f1ae24d112e3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Experiment 1 finetune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfinetune_readmission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransfer_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_or_discharge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'3days/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-148-56aa35deaee9>\u001b[0m in \u001b[0;36mfinetune_readmission\u001b[0;34m(gmodel, cmodel, transfer_weight, max_length, train_size, test_size, num_epochs, early_or_discharge)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"------------- start of epoch {epoch+1} ----------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre_test_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-160-7085586eb068>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, train_loader, optimizer, epoch, loss_fn, log_interval)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}